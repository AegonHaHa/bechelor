\chapter{总结与展望}
\label{chp:future}

\par 本章对CW-Cache当前完成的工作进行总结，并对CW-Cache未来的研究方向与计划进行展望。

\section{工作总结}

\par 我们注意到数据密集型集群中出现的负载均衡的问题，并且在文献调研中发现，研究人员几乎都关注一般意义上的文件的负载均衡，缺少对结构化数据的文件的特别关注。本文研究发现，集群里对结构化数据（数据表）的各个列的访问热度存在较大倾斜，且两列的热度越高，二者被共同访问的概率也越高。基于这个发现，本文设计、分析、开发了CW-Cache系统，希望实现结构化数据在列级别的负载均衡。目前CW-Cache实现了Bundle-K方案，即将热度排在前$K$的列“捆绑”在一起进行复制，复制$r$份。本文对Bundle-K方案进行了数学建模，给定一段时间内统计的各个列的热度和SQL查询任务的数量，求出当前最优的$K$和$r$。

\par 我们在分布式内存文件系统Alluxio上实现了CW-Cache，尽量只利用Alluxio能够获得的信息，避免与上层计算框架的耦合。


\section{未来展望}

\par 在完成毕业论文的写作与答辩后，我仍将继续进行这个项目，采用Bundle-K方案的CW-Cache远远达不到完善的程度，还有很多工作于研究亟待进行，这个方案仅仅适用于一部分案例，还存在不少问题：

\begin{itemize}
    \item CW-Cache识别列是借助文件URI、偏移量和读取长度，实质上已经放弃了文件存储的结构化数据的语义信息，是和系统实现的妥协。本身Parquet文件在存储时各个列在物理上并不连续，导致在CW-Cache系统看来，每一个列是由若干“文件片段”构成的。能否在不增加上下层耦合度的情况下再次引入列的语义信息，这是否能提高系统的性能，留待探索。
    \item 考虑列的共同访问模式，当前CW-Cache系统是设置一个时间窗口，来判断相邻的被访问的列是否同属一个SQL查询任务。现在我们认为当Spark SQL解析SQL语句后，会并发地取获取需要访问的列，于是将这个窗口设置得比较小，但情况是否真的全是这样呢？此外，只有一个用户使用CW-Cache时还好，当多个用户同时使用时，结果将会不准确，我们需要想其他的办法避开。
    \item Bundle-K方案也许不够灵活，Bundle-K有两个极端特例，一个是Bundle-1，也就是把热度最高的列复制多份并分散在集群中缓存，如果这张表的访问热度倾斜很严重，那么Bundle-1可能取得好的效果；另一个是Bundle-N，也就是全表复制，相当于现有的复制方案，这个可以完全避免表内数据shuffle，但是复制成本高。我们现在的Bundle-K是这两个方案的折中，但是我们目前将这$K$列视作整体一起复制，复制的份数相同，不够灵活。Bundle-K应用在图\ref{fig:calc-dd}、\ref{fig:emul-dd}、\ref{fig:emul-wr}、\ref{fig:emul-ws}所示的表上有不错的效果，因为当$K$比较小的时候，随着$K$的上升，前$K$列组成的副本能承担大量的负载，而图~\ref{fig:calc-wr}、\ref{fig:calc-ws}的曲线接近线性增长，收益不大。
\end{itemize}

\par 此外，数据shuffling与数据放置的位置、网络通信状况、任务调度等因素均有关，非常复杂，它产生的影响难以通过数学建模进行研究。我们非常希望有一个方法能够以较小的复制开销实现负载均衡，同时能够避免shuffling，而这样的one-size-fit-all的方法几乎是不存在的，还是需要在不同方案间考虑不同场景进行取舍。